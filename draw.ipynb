{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "import random\n",
    "from tensorflow.examples.tutorials import mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_loaded = 'mnist' #svhn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############################################ Reading the SVHM training data ################################\n",
    "svhm_dataset_mat = \"./../Datasets/SVHN/train_32x32.mat\"\n",
    "svhn = scipy.io.loadmat(svhm_dataset_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3, 73257)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svhn_data = svhn['X']\n",
    "svhn_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "############################################ Reading the MNIST training data ################################\n",
    "data = mnist.input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################################ Reading the SVHM training data ################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.train.next_batch(100))[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################################# Useful funtions ########################################\n",
    "def ims(name, img):\n",
    "    scipy.misc.toimage(img, cmin=0, cmax=1).save(name)\n",
    "    \n",
    "def merge(images, size):\n",
    "    h, w = images.shape[1], images.shape[2]\n",
    "    img = np.zeros((h * size[0], w * size[1]))\n",
    "    #print h, w\n",
    "    for idx, image in enumerate(images):\n",
    "        i = idx % size[1]\n",
    "        j = idx / size[1]\n",
    "        #print i,j\n",
    "        img[j*h:(j*h)+h, i*w:(i*w)+w] = image\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############################################# Model Parameters ########################################\n",
    "\n",
    "#For MNIST\n",
    "A, B = 28, 28\n",
    "img_size = A * B # IMage size/Canvas Size\n",
    "batch_size = 64 #Batch Size\n",
    "read_att = True #Whether read attention used\n",
    "write_att = True #Whether write attention used\n",
    "enc_size = 256 #Hidden units in LSTM for enc\n",
    "dec_size = 256 #Hidden units in LSTM for dec\n",
    "z_size = 10 #QSampler Output size\n",
    "g_read = 5 #Glimpse dim to read width, height\n",
    "g_write = 5\n",
    "seq_len = 10 #Sequence length for the backporp\n",
    "\n",
    "#For SVHN\n",
    "'''\n",
    "A, B = 28, 28\n",
    "img_size = A * B # IMage size/Canvas Size\n",
    "batch_size = 64 #Batch Size\n",
    "read_att = True #Whether read attention used\n",
    "write_att = True #Whether write attention used\n",
    "enc_size = 256 #Hidden units in LSTM for enc\n",
    "dec_size = 256 #Hidden units in LSTM for dec\n",
    "z_size = 10 #QSampler Output size\n",
    "g_read = 5 #Glimpse dim to read width, height\n",
    "g_write = 5\n",
    "seq_len = 10 #Sequence length for the backporp\n",
    "'''\n",
    "\n",
    "learning_rate = 1e-3 #Learning rate\n",
    "epsilon = 1e-8\n",
    "epochs = 10000\n",
    "SHARE = None\n",
    "\n",
    "canvas = [0] * seq_len #Canvases used for writing\n",
    "mu, sigma, logsigma = [0] * seq_len, [0] * seq_len,[0] * seq_len #Used in Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############################################# Model funtions ##########################################\n",
    "#Affine transormation y = W(x) + b, where x is batch_size * feature_size\n",
    "def linearOP(x, op_size):\n",
    "    W = tf.get_variable(\"W\", shape = [x.get_shape()[1], op_size])\n",
    "    b = tf.get_variable(\"b\", shape = op_size ,initializer=tf.constant_initializer(0.0))\n",
    "    return tf.matmul(x,W)+b\n",
    "\n",
    "#Encoder step \n",
    "def encode(input,state):\n",
    "    with tf.variable_scope(\"encode\", reuse = SHARE):\n",
    "        return enc(input, state)\n",
    "\n",
    "#Decoder Step\n",
    "def decode(input, state):\n",
    "    with tf.variable_scope(\"decode\", reuse = SHARE):\n",
    "        return dec(input, state)\n",
    "    \n",
    "#Sample z_t ~ Q(Z|h_enc) from reparametarization trick\n",
    "def QSample(h_enc):\n",
    "    with tf.variable_scope(\"Mu\", reuse = SHARE):\n",
    "        mu = linearOP(h_enc, z_size)\n",
    "    with tf.variable_scope(\"sigma\", reuse = SHARE):\n",
    "        logsigma = linearOP(h_enc, z_size)\n",
    "        sigma = tf.exp(logsigma)\n",
    "    return (mu + sigma * sdn),mu, sigma, logsigma\n",
    "\n",
    "#Applying binary cross ent. between two distn\n",
    "def binary_crossentropy(t,o):\n",
    "    return -(t*tf.log(o+epsilon) + (1.0-t)*tf.log(1.0-o+epsilon))\n",
    "\n",
    "\n",
    "# given a hidden decoder layer; locate where to put attention filters\n",
    "def attn_window(scope, h_dec, N):\n",
    "    with tf.variable_scope(scope, reuse=SHARE):\n",
    "        parameters = linearOP(h_dec, N)\n",
    "    # gx_, gy_: center of 2d gaussian on a scale of -1 to 1\n",
    "    gx_, gy_, log_sigma2, log_delta, log_gamma = tf.split(1,5,parameters)\n",
    "\n",
    "    # move gx/gy to be a scale of -imgsize to +imgsize\n",
    "    gx = (A+1)/2 * (gx_ + 1)\n",
    "    gy = (B+1)/2 * (gy_ + 1)\n",
    "\n",
    "    sigma2 = tf.exp(log_sigma2)\n",
    "    # stride/delta: how far apart these patches will be\n",
    "    delta = (max(A,B) - 1) / ((N-1) * tf.exp(log_delta))\n",
    "    # returns [Fx, Fy, gamma]\n",
    "    return filterbank(gx,gy,sigma2,delta,N) + (tf.exp(log_gamma),)\n",
    "    \n",
    "    \n",
    "# Given a center, distance, and spread, Construct [N x N] patches of gaussian filters\n",
    "# represented by Fx = horizontal gaussian, Fy = vertical guassian\n",
    "def filterbank(gx, gy, sigma2, delta,N):\n",
    "    # 1 x N, look like [[0,1,2,3,4]]\n",
    "    grid_i = tf.reshape(tf.cast(tf.range(N), tf.float32),[1, -1])\n",
    "    # centers for the individual patches\n",
    "    mu_x = gx + (grid_i - N/2 - 0.5) * delta\n",
    "    mu_y = gy + (grid_i - N/2 - 0.5) * delta\n",
    "    mu_x = tf.reshape(mu_x, [-1,N, 1])\n",
    "    mu_y = tf.reshape(mu_y, [-1,N, 1])\n",
    "    # 1 x 1 x imgsize, looks like [[[0,1,2,3,4,...,27]]]\n",
    "    a = tf.reshape(tf.cast(tf.range(A), tf.float32), [1, 1, -1])\n",
    "    b = tf.reshape(tf.cast(tf.range(B), tf.float32), [1, 1, -1])\n",
    "    # list of gaussian curves for x and y\n",
    "    sigma2 = tf.reshape(sigma2, [-1, 1, 1])\n",
    "    Fx = tf.exp(-tf.square((a - mu_x) / (2*sigma2)))\n",
    "    Fy = tf.exp(-tf.square((b - mu_x) / (2*sigma2)))# batch x N x B\n",
    "    # normalize so area-under-curve = 1\n",
    "    Fx = Fx / tf.maximum(tf.reduce_sum(Fx,2,keep_dims=True),epsilon)\n",
    "    Fy = Fy / tf.maximum(tf.reduce_sum(Fy,2,keep_dims=True),epsilon)\n",
    "    return Fx, Fy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############################################ Model Details#############################################\n",
    "x = tf.placeholder(tf.float32, [batch_size, img_size])\n",
    "# Qsampler noise which is Std. Normal, used in geting z_t via reparametization of this shape\n",
    "sdn = tf.random_normal((batch_size,z_size), mean=0, stddev=1) \n",
    "enc = tf.nn.rnn_cell.LSTMCell(num_units=enc_size, state_is_tuple=True)\n",
    "dec = tf.nn.rnn_cell.LSTMCell(num_units=dec_size, state_is_tuple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read operation with/without attention\n",
    "def read(x, xhat, h_dec_prev):\n",
    "    if(read_att == False):\n",
    "        return tf.concat(1, [x, xhat])\n",
    "    elif(read_att == True):\n",
    "        Fx, Fy, gamma = attn_window(\"read\", h_dec_prev, g_read)    \n",
    "        #Apply the filter over the img(batch_size * img_size)\n",
    "        def filter_img(img, Fx, Fy, gamma, N):\n",
    "            Fxt=tf.transpose(Fx,perm=[0,2,1])\n",
    "            img=tf.reshape(img,[-1,B,A])\n",
    "            # Apply the gaussian patches:\n",
    "            # A = B = imgsize (they are all the image size)\n",
    "            # attn = height/length of attention patches\n",
    "            # allfilters = [attn, vert] * [imgsize,imgsize] * [horiz, attn] (Eq 27)\n",
    "            # we have batches, so the full batch_matmul equation looks like:\n",
    "            # [1, 1, vert] * [batchsize,imgsize,imgsize] * [1, horiz, 1]\n",
    "            glimpse=tf.batch_matmul(Fy,tf.batch_matmul(img,Fxt))\n",
    "            glimpse=tf.reshape(glimpse,[-1,N*N])\n",
    "            return glimpse*tf.reshape(gamma,[-1,1])\n",
    "        x = filter_img(x, Fx, Fy, gamma, g_read) #batch_size * (g_read * g_read)\n",
    "        xhat = filter_img(xhat, Fx, Fy, gamma, g_read)\n",
    "        return tf.concat(1, [x, xhat]) #Concatinating all the features together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Write operation with/without attention\n",
    "def write(h_dec):\n",
    "    if(write_att == False):\n",
    "        with tf.variable_scope(\"writeWithoutAtten\", reuse = SHARE):\n",
    "            return linearOP(x, img_size)\n",
    "    elif(write_att == True):\n",
    "        with tf.variable_scope(\"writeAtten\", reuse=SHARE):\n",
    "            w = linearOP(h_dec, g_write*g_write)\n",
    "        N=g_write\n",
    "        w = tf.reshape(w, [batch_size, N,N])\n",
    "        Fx, Fy, gamma = attn_window(\"write\", h_dec, g_write)\n",
    "        Fyt = tf.transpose(Fy, perm=[0,2,1])\n",
    "        # [vert, attn_n] * [attn_n, attn_n] * [attn_n, horiz]\n",
    "        wr = tf.batch_matmul(Fyt, tf.batch_matmul(w, Fx))\n",
    "        wr = tf.reshape(wr, [batch_size, B*A])\n",
    "        return wr * tf.reshape(1.0/gamma, [-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initial State Variables\n",
    "h_dec_prev = tf.zeros([batch_size, dec_size])\n",
    "dec_state = dec.zero_state(batch_size, tf.float32)\n",
    "enc_state = enc.zero_state(batch_size, tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Progress through time steps, equations defined in paper\n",
    "for t in range(seq_len):\n",
    "    c_prev = tf.zeros([batch_size, img_size]) if t == 0 else canvas[t-1]\n",
    "    xhat = x - tf.sigmoid(c_prev) #error img = org iamge - generated img\n",
    "    r_t = read(x, xhat, h_dec_prev) #read the cropped/full image\n",
    "    h_enc, enc_state = encode(tf.concat(1, [r_t, h_dec_prev]),enc_state)\n",
    "    z_t, mu[t], sigma[t], logsigma[t] = QSample(h_enc)\n",
    "    h_dec, dec_state = decode(z_t,dec_state)\n",
    "    canvas[t] = c_prev + write(h_dec)\n",
    "    h_dec_prev = h_dec\n",
    "    SHARE = True #USe previously made variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Loss funtion implementation\n",
    "xdash = tf.sigmoid(canvas[-1]) #Squissh the loss from -1 to 1, then take bin cross_entropy for batch\n",
    "Lx = tf.reduce_mean(tf.reduce_sum(binary_crossentropy(x, xdash), 1))\n",
    "\n",
    "kl_ = [0] *  seq_len\n",
    "for t in range(seq_len):\n",
    "    mu_t = tf.square(mu[t])\n",
    "    sigma_t = tf.square(sigma[t])\n",
    "    logsigma_t = logsigma[t]\n",
    "    kl_[t] = 0.5*tf.reduce_sum(mu_t+sigma_t-2*logsigma_t,1)#Corressponding to 1 x batch_size\n",
    "KL = tf.add_n(kl_)#Summing up kl terms from 1:T\n",
    "KL = KL - seq_len * 0.5\n",
    "Ly = tf.reduce_mean(KL)\n",
    "\n",
    "totalLoss = Lx + Ly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Optimizer\n",
    "optimizer=tf.train.AdamOptimizer(learning_rate, beta1=0.5)\n",
    "grads=optimizer.compute_gradients(totalLoss)\n",
    "for i,(g,v) in enumerate(grads):\n",
    "    if g is not None:\n",
    "        grads[i]=(tf.clip_by_norm(g,5),v) # clip gradients\n",
    "train_op=optimizer.apply_gradients(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 genloss 544.305115 latloss 46.437206\n",
      "iter 500 genloss 193.861420 latloss 46.887955\n",
      "iter 1000 genloss 171.391205 latloss 47.238720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peyush/tEnv/lib/python2.7/site-packages/ipykernel/__main__.py:12: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1500 genloss 155.149567 latloss 47.900330\n",
      "iter 2000 genloss 149.505829 latloss 47.444664\n",
      "iter 2500 genloss 143.341888 latloss 47.010830\n",
      "iter 3000 genloss 129.464523 latloss 47.433628\n",
      "iter 3500 genloss 125.463028 latloss 47.291893\n",
      "iter 4000 genloss 121.374557 latloss 47.369228\n",
      "iter 4500 genloss 107.398605 latloss 47.288170\n",
      "iter 5000 genloss 106.758438 latloss 47.087303\n",
      "iter 5500 genloss 101.534348 latloss 47.025978\n",
      "iter 6000 genloss 89.629601 latloss 46.828667\n",
      "iter 6500 genloss 91.066574 latloss 46.933029\n",
      "iter 7000 genloss 88.702499 latloss 46.593971\n",
      "iter 7500 genloss 83.561974 latloss 46.528999\n",
      "iter 8000 genloss 78.266006 latloss 46.581345\n",
      "iter 8500 genloss 87.610870 latloss 46.578934\n",
      "iter 9000 genloss 81.244064 latloss 46.488026\n",
      "iter 9500 genloss 82.113327 latloss 46.499725\n"
     ]
    }
   ],
   "source": [
    "#Training model\n",
    "sess = tf.Session()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "for i in xrange(epochs):\n",
    "    X_train, _ = data.train.next_batch(batch_size)\n",
    "    feed_dict = {x: X_train}\n",
    "    cs, gen_loss, lat_loss, _ = sess.run([canvas, Lx, Ly, train_op], feed_dict=feed_dict)\n",
    "   \n",
    "    if i % 500 == 0:\n",
    "        print \"iter %d genloss %f latloss %f\" % (i, gen_loss, lat_loss)\n",
    "        cs = 1.0/(1.0+np.exp(-np.array(cs))) # x_recons=sigmoid(canvas)\n",
    "        for cs_iter in xrange(seq_len):\n",
    "            results = cs[cs_iter]\n",
    "            results_square = np.reshape(results, [-1, A, B])\n",
    "            #print results_square.shape\n",
    "            ims(\"results/\"+str(i)+\"-step-\"+str(cs_iter)+\".jpg\",merge(results_square,[8,8]))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
